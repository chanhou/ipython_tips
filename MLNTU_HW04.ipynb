{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "import scipy.linalg as sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = np.genfromtxt(\"./hw4_train.dat.txt\", dtype=float, delimiter='') \n",
      "data_train = np.insert(data_train, 0, 1, axis=1)\n",
      "data_test = np.genfromtxt(\"./hw4_test.dat.txt\", dtype=float, delimiter='') \n",
      "data_test = np.insert(data_test, 0, 1, axis=1)\n",
      "data_train[:,0:3].shape\n",
      "\n",
      "# 10*np.identity(3)\n",
      "# sp.inv((data_test[:,0:3].T.dot(data_test[:,0:3])+ np.identity(3))).dot(data_test[:,0:3].T).dot(data_test[:,-1])\n",
      "# a = 10**np.linspace(-10, 2, num=13)\n",
      "# len(np.array([10]))\n",
      "# len(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 146,
       "text": [
        "(200, 3)"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train = np.array(data_train[:,-1])\n",
      "y_test = np.array(data_test[:,-1])\n",
      "x_train = np.array(data_train[:,0:3])\n",
      "x_test = np.array(data_test[:,0:3])\n",
      "lamda = 10**np.linspace(-10, 2, num=13)\n",
      "\n",
      "x_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 195,
       "text": [
        "(200, 3)"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Q13 - Q14::"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ridge_regression_13_14(Q13):    \n",
      "    I = np.identity(len(data_train[0])-1)\n",
      "    \n",
      "    if Q13:\n",
      "        lamda = np.array([10])\n",
      "    else:\n",
      "        lamda = 10**np.linspace(-10, 2, num=13)\n",
      "        \n",
      "    for i in range(len(lamda)):\n",
      "        weights = sp.inv((x_train.T.dot(x_train)+ lamda[i]*np.identity(3))).dot(x_train.T).dot(y_train)\n",
      "        \n",
      "        ######### \n",
      "        # E_in counting\n",
      "        #########\n",
      "        hypo_in = weights.dot( x_train.T )\n",
      "        \n",
      "        hypo_in[hypo_in >= 0] = 1\n",
      "        hypo_in[hypo_in < 0] = -1\n",
      "        \n",
      "        E_in = hypo_in - y_train\n",
      "        # counting result is error\n",
      "        E_in = np.count_nonzero(E_in)\n",
      "        E_in = (1.0*E_in)/len(y_train)\n",
      "        \n",
      "        ########\n",
      "        # record the best result\n",
      "        ########\n",
      "        if i is 0:\n",
      "            E_in_best = E_in\n",
      "            lamda_best = np.log10(lamda[i])\n",
      "            weights_best = weights\n",
      "        elif E_in <= E_in_best:\n",
      "            print 'possible lamda::',np.log10(lamda[i])\n",
      "            E_in_best = E_in\n",
      "            lamda_best = np.log10(lamda[i])\n",
      "            weights_best = weights\n",
      "    \n",
      "    print 'lamda_best::',lamda_best\n",
      "    #     print 'weights::',weights_best\n",
      "    \n",
      "    ######### \n",
      "    # E_out counting\n",
      "    #########\n",
      "    hypo_out = weights_best.dot( x_test.T )\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    hypo_out[hypo_out >= 0] = 1\n",
      "    hypo_out[hypo_out < 0] = -1\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    E_out = hypo_out - y_test\n",
      "    # counting result is error\n",
      "    E_out = np.count_nonzero(E_out)\n",
      "    E_out = (1.0*E_out)/len(y_test)\n",
      "    \n",
      "    return E_in_best, E_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Q 13: with lambda = 10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_13_14(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "lamda_best:: 1.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 198,
       "text": [
        "(0.05, 0.045)"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q14:: with $log_{10}$$\\lambda$={2,1,...,-10} , min $E_{in}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_13_14(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "possible lamda:: -9.0\n",
        "possible lamda:: -8.0\n",
        "lamda_best:: -8.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 199,
       "text": [
        "(0.015, 0.02)"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q15:: with $log_{10}$$\\lambda$={2,1,...,-10} , min $E_{out}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ridge_regression_15():    \n",
      "    I = np.identity(len(data_train[0])-1)\n",
      "    \n",
      "    for i in range(len(lamda)):\n",
      "        weights = sp.inv((x_train.T.dot(x_train)+ lamda[i]*np.identity(3))).dot(x_train.T).dot(y_train)\n",
      "        \n",
      "        ######### \n",
      "        # E_out counting\n",
      "        #########\n",
      "        hypo_out = weights.dot( x_test.T )\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        hypo_out[hypo_out >= 0] = 1\n",
      "        hypo_out[hypo_out < 0] = -1\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        E_out = hypo_out - y_test\n",
      "        # counting result is error\n",
      "        E_out = np.count_nonzero(E_out)\n",
      "        E_out = (1.0*E_out)/len(y_test)\n",
      "        \n",
      "        ########\n",
      "        # record the best result\n",
      "        ########\n",
      "        if i is 0:\n",
      "            E_out_best = E_out\n",
      "            lamda_best = np.log10(lamda[i])\n",
      "            weights_best = weights\n",
      "        elif E_out <= E_out_best:\n",
      "            print 'possible lamda::',np.log10(lamda[i])\n",
      "            E_out_best = E_out\n",
      "            lamda_best = np.log10(lamda[i])\n",
      "            weights_best = weights\n",
      "        \n",
      "        \n",
      "    print 'lamda_best::',lamda_best\n",
      "\n",
      "    ######### \n",
      "    # E_in counting\n",
      "    #########\n",
      "    hypo_in = weights_best.dot( x_train.T )\n",
      "    \n",
      "    hypo_in[hypo_in >= 0] = 1\n",
      "    hypo_in[hypo_in < 0] = -1\n",
      "    \n",
      "    E_in = hypo_in - y_train\n",
      "    # counting result is error\n",
      "    E_in = np.count_nonzero(E_in)\n",
      "    E_in = (1.0*E_in)/len(y_train)\n",
      "        \n",
      "    return E_in, E_out_best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_15()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "possible lamda:: -9.0\n",
        "possible lamda:: -8.0\n",
        "possible lamda:: -7.0\n",
        "lamda_best:: -7.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 201,
       "text": [
        "(0.03, 0.015)"
       ]
      }
     ],
     "prompt_number": 201
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q16:: with $log_{10}$$\\lambda$={2,1,...,-10} , 120/80 spliting,  min $E_{train}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_t = np.array(data_train[0:120,-1])\n",
      "x_train_t = np.array(data_train[0:120,0:3])\n",
      "\n",
      "y_train_val = np.array(data_train[120:200,-1])\n",
      "x_train_val = np.array(data_train[120:200,0:3])\n",
      "\n",
      "y_test_v = np.array(data_test[:,-1])\n",
      "x_test_v = np.array(data_test[:,0:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ridge_regression_16():    \n",
      "    \n",
      "    I = np.identity(len(data_train[0])-1)\n",
      "    \n",
      "    for i in range(len(lamda)):\n",
      "        weights = sp.inv((x_train_t.T.dot(x_train_t)+ lamda[i]*np.identity(3))).dot(x_train_t.T).dot(y_train_t)\n",
      "        \n",
      "        ######### \n",
      "        # E_train counting\n",
      "        #########\n",
      "        hypo_train = weights.dot( x_train_t.T )\n",
      "        \n",
      "        hypo_train[hypo_train >= 0] = 1\n",
      "        hypo_train[hypo_train < 0] = -1\n",
      "        \n",
      "        E_train = hypo_train - y_train_t\n",
      "        # counting result is error\n",
      "        E_train = np.count_nonzero(E_train)\n",
      "        E_train = (1.0*E_train)/len(y_train_t)\n",
      "        \n",
      "        ########\n",
      "        # record the best result\n",
      "        ########\n",
      "        if i is 0:\n",
      "            E_train_best = E_train\n",
      "            lamda_best = np.log10(lamda[i])\n",
      "            weights_best = weights\n",
      "        elif E_train <= E_train_best:\n",
      "            print 'possible lamda::',np.log10(lamda[i])\n",
      "            E_train_best = E_train\n",
      "            lamda_best = np.log10(lamda[i])\n",
      "            weights_best = weights\n",
      "    \n",
      "    print 'lamda_best::',lamda_best\n",
      "    #     print 'weights::',weights_best\n",
      "    \n",
      "    ######### \n",
      "    # E_val counting\n",
      "    #########\n",
      "    hypo_val = weights_best.dot( x_train_val.T )\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    hypo_val[hypo_val >= 0] = 1\n",
      "    hypo_val[hypo_val < 0] = -1\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    E_val = hypo_val - y_train_val\n",
      "    # counting result is error\n",
      "    E_val = np.count_nonzero(E_val)\n",
      "    E_val = (1.0*E_val)/len(y_train_val)\n",
      "    \n",
      "    \n",
      "    ######### \n",
      "    # E_out counting\n",
      "    #########\n",
      "    hypo_out = weights_best.dot( x_test_v.T )\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    hypo_out[hypo_out >= 0] = 1\n",
      "    hypo_out[hypo_out < 0] = -1\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    E_out = hypo_out - y_test_v\n",
      "    # counting result is error\n",
      "    E_out = np.count_nonzero(E_out)\n",
      "    E_out = (1.0*E_out)/len(y_test_v)\n",
      "    \n",
      "    return E_train_best,E_val, E_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_16()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "possible lamda:: -9.0\n",
        "possible lamda:: -8.0\n",
        "lamda_best:: -8.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 204,
       "text": [
        "(0.0, 0.05, 0.025)"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q17 & Q18"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ridge_regression_17_18( whole ):    \n",
      "    \n",
      "    I = np.identity(len(data_train[0])-1)\n",
      "    \n",
      "    for i in range(len(lamda)):\n",
      "        weights = sp.inv((x_train_t.T.dot(x_train_t)+ lamda[i]*np.identity(3))).dot(x_train_t.T).dot(y_train_t)\n",
      "        \n",
      "        ######### \n",
      "        # E_val counting\n",
      "        #########\n",
      "        hypo_val = weights.dot( x_train_val.T )\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        hypo_val[hypo_val >= 0] = 1\n",
      "        hypo_val[hypo_val < 0] = -1\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        E_val = hypo_val - y_train_val\n",
      "        # counting result is error\n",
      "        E_val = np.count_nonzero(E_val)\n",
      "        E_val = (1.0*E_val)/len(y_train_val)\n",
      "        \n",
      "        \n",
      "        ########\n",
      "        # record the best result\n",
      "        ########\n",
      "        if i is 0:\n",
      "            E_val_best = E_val\n",
      "            lamda_best = lamda[i]\n",
      "            weights_best = weights\n",
      "        elif E_val <= E_val_best:\n",
      "            print 'possible lamda::',np.log10(lamda[i])\n",
      "            E_val_best = E_val\n",
      "            lamda_best = lamda[i]\n",
      "            weights_best = weights\n",
      "    \n",
      "    print 'lamda_best::',np.log10(lamda_best)\n",
      "    #     print 'weights::',weights_best\n",
      "    \n",
      "    \n",
      "    ######### \n",
      "    # E_train counting\n",
      "    #########\n",
      "    hypo_train = weights_best.dot( x_train_t.T )\n",
      "    \n",
      "    hypo_train[hypo_train >= 0] = 1\n",
      "    hypo_train[hypo_train < 0] = -1\n",
      "    \n",
      "    E_train = hypo_train - y_train_t\n",
      "    # counting result is error\n",
      "    E_train = np.count_nonzero(E_train)\n",
      "    E_train = (1.0*E_train)/len(y_train_t)\n",
      "\n",
      "    ######### \n",
      "    # E_out counting\n",
      "    #########\n",
      "    hypo_out = weights_best.dot( x_test_v.T )\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    hypo_out[hypo_out >= 0] = 1\n",
      "    hypo_out[hypo_out < 0] = -1\n",
      "    #     print 'hypo_out::',hypo_out\n",
      "    \n",
      "    E_out = hypo_out - y_test_v\n",
      "    # counting result is error\n",
      "    E_out = np.count_nonzero(E_out)\n",
      "    E_out = (1.0*E_out)/len(y_test_v)\n",
      "    \n",
      "    if whole:\n",
      "        \n",
      "        weights = sp.inv((x_train.T.dot(x_train)+ lamda_best*np.identity(3))).dot(x_train.T).dot(y_train)\n",
      "\n",
      "        ######### \n",
      "        # E_in counting\n",
      "        #########\n",
      "        hypo_in = weights.dot( x_train.T )\n",
      "        \n",
      "        hypo_in[hypo_in >= 0] = 1\n",
      "        hypo_in[hypo_in < 0] = -1\n",
      "        \n",
      "        E_in = hypo_in - y_train\n",
      "        # counting result is error\n",
      "        E_in = np.count_nonzero(E_in)\n",
      "        E_in = (1.0*E_in)/len(y_train)\n",
      "        \n",
      "        ######### \n",
      "        # E_out counting\n",
      "        #########\n",
      "        hypo_out = weights.dot( x_test.T )\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        hypo_out[hypo_out >= 0] = 1\n",
      "        hypo_out[hypo_out < 0] = -1\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        E_out = hypo_out - y_test\n",
      "        # counting result is error\n",
      "        E_out = np.count_nonzero(E_out)\n",
      "        E_out = (1.0*E_out)/len(y_test)\n",
      "        \n",
      "        return E_in, E_out\n",
      "    \n",
      "    return E_train,E_val_best, E_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q17:: with $log_{10}$$\\lambda$={2,1,...,-10} , 120/80 spliting,  min $E_{val}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_17_18(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "possible lamda:: -9.0\n",
        "possible lamda:: -8.0\n",
        "possible lamda:: -7.0\n",
        "possible lamda:: -6.0\n",
        "possible lamda:: -5.0\n",
        "possible lamda:: -4.0\n",
        "possible lamda:: -3.0\n",
        "possible lamda:: -2.0\n",
        "possible lamda:: -1.0\n",
        "possible lamda:: 0.0\n",
        "lamda_best:: 0.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "(0.03333333333333333, 0.0375, 0.028)"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q18:: with $log_{10}$$\\lambda$={2,1,...,-10} , previous result on whole data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_17_18(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "possible lamda:: -9.0\n",
        "possible lamda:: -8.0\n",
        "possible lamda:: -7.0\n",
        "possible lamda:: -6.0\n",
        "possible lamda:: -5.0\n",
        "possible lamda:: -4.0\n",
        "possible lamda:: -3.0\n",
        "possible lamda:: -2.0\n",
        "possible lamda:: -1.0\n",
        "possible lamda:: 0.0\n",
        "lamda_best:: 0.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "(0.035, 0.02)"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Q19&20"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.array([[1,2],[2,1]])\n",
      "b = np.array([[3,4],[132,24],[123,245]])\n",
      "np.concatenate((a, b), axis=0)\n",
      "np.concatenate((np.array(data_train[0:40,0:3]),np.array(data_train[80:200,0:3]))  , axis=0)\n",
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 180,
       "text": [
        "array([[1, 2],\n",
        "       [2, 1]])"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result,er = {\n",
      "  0: (np.array(data_train[40:200,0:3]),np.array(data_train[40:200,-1])),\n",
      "  1: (np.concatenate((np.array(data_train[0:40,0:3]),np.array(data_train[80:200,0:3]))  , axis=0)\n",
      "      ,np.concatenate((np.array(data_train[0:40,-1]),np.array(data_train[80:200,-1]))  , axis=0)) ,\n",
      "  2: (4,5)\n",
      "}[0]\n",
      "# print er\n",
      "a = [2,3,4]\n",
      "a.append(1)\n",
      "print np.array(a).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.5\n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ridge_regression_19_20( whole ):    \n",
      "    \n",
      "    I = np.identity(len(data_train[0])-1)\n",
      "    \n",
      "    for i in range(len(lamda)):\n",
      "        number = 0\n",
      "        E_cv = []\n",
      "        \n",
      "        if i is 0:\n",
      "            E_cv_best = 1\n",
      "            lamda_best = lamda[i]\n",
      "\n",
      "        for ccc in range(5):\n",
      "            x_train_cv , y_train_cv = {\n",
      "                0: (np.array(data_train[40:200,0:3]),np.array(data_train[40:200,-1])),\n",
      "                1: (np.concatenate((np.array(data_train[0:40,0:3]),np.array(data_train[80:200,0:3]))  , axis=0)\n",
      "                    ,np.concatenate((np.array(data_train[0:40,-1]),np.array(data_train[80:200,-1]))  , axis=0)) ,\n",
      "                2: (np.concatenate((np.array(data_train[0:80,0:3]),np.array(data_train[120:200,0:3]))  , axis=0)\n",
      "                    ,np.concatenate((np.array(data_train[0:80,-1]),np.array(data_train[120:200,-1]))  , axis=0)) ,\n",
      "                3: (np.concatenate((np.array(data_train[0:120,0:3]),np.array(data_train[160:200,0:3]))  , axis=0)\n",
      "                    ,np.concatenate((np.array(data_train[0:120,-1]),np.array(data_train[160:200,-1]))  , axis=0)) ,\n",
      "                4: (np.array(data_train[0:160,0:3]),np.array(data_train[0:160,-1]))\n",
      "            }[ccc]\n",
      "            \n",
      "            x_val_cv = np.array(data_train[number:(number+40),0:3])\n",
      "            y_val_cv = np.array(data_train[number:(number+40),-1])\n",
      "            number += 40\n",
      "            \n",
      "            weights = sp.inv((x_train_cv.T.dot(x_train_cv)+ lamda[i]*np.identity(3))).dot(x_train_cv.T).dot(y_train_cv)\n",
      "            \n",
      "            ######### \n",
      "            # E_cv counting\n",
      "            #########\n",
      "            hypo_train = weights.dot( x_val_cv.T )\n",
      "            \n",
      "            hypo_train[hypo_train >= 0] = 1\n",
      "            hypo_train[hypo_train < 0] = -1\n",
      "            \n",
      "            E_vall = hypo_train - y_val_cv\n",
      "            # counting result is error\n",
      "            E_vall = np.count_nonzero(E_vall)\n",
      "#             print E_cv\n",
      "            E_vall = (1.0*E_vall)/len(y_val_cv)\n",
      "            \n",
      "            E_cv.append(E_vall)\n",
      "        \n",
      "        E_cv = np.array(E_cv).mean()\n",
      "        print E_cv, lamda[i]\n",
      "            \n",
      "        ########\n",
      "        # record the best result\n",
      "        ########\n",
      "        if E_cv <= E_cv_best:\n",
      "            # print 'possible lamda::',np.log10(lamda[i])\n",
      "            E_cv_best = E_cv\n",
      "            lamda_best = lamda[i]\n",
      "            weights_best = weights\n",
      "    \n",
      "    print 'lamda_best::',np.log10(lamda_best)\n",
      "    #     print 'weights::',weights_best\n",
      "    \n",
      "    if whole:\n",
      "        \n",
      "        weights = sp.inv((x_train.T.dot(x_train)+ lamda_best*np.identity(3))).dot(x_train.T).dot(y_train)\n",
      "\n",
      "        ######### \n",
      "        # E_in counting\n",
      "        #########\n",
      "        hypo_in = weights.dot( x_train.T )\n",
      "        \n",
      "        hypo_in[hypo_in >= 0] = 1\n",
      "        hypo_in[hypo_in < 0] = -1\n",
      "        \n",
      "        E_in = hypo_in - y_train\n",
      "        # counting result is error\n",
      "        E_in = np.count_nonzero(E_in)\n",
      "        E_in = (1.0*E_in)/len(y_train)\n",
      "        \n",
      "        ######### \n",
      "        # E_out counting\n",
      "        #########\n",
      "        hypo_out = weights.dot( x_test.T )\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        hypo_out[hypo_out >= 0] = 1\n",
      "        hypo_out[hypo_out < 0] = -1\n",
      "        #     print 'hypo_out::',hypo_out\n",
      "        \n",
      "        E_out = hypo_out - y_test\n",
      "        # counting result is error\n",
      "        E_out = np.count_nonzero(E_out)\n",
      "        E_out = (1.0*E_out)/len(y_test)\n",
      "        \n",
      "        return E_in, E_out\n",
      "    \n",
      "    return E_cv_best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q19:: with $log_{10}$$\\lambda$={2,1,...,-10} , min $E_{cv}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_19_20(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.05 1e-10\n",
        "0.05 1e-09\n",
        "0.03 1e-08\n",
        "0.035 1e-07\n",
        "0.035 1e-06\n",
        "0.035 1e-05\n",
        "0.035 0.0001\n",
        "0.035 0.001\n",
        "0.035 0.01\n",
        "0.035 0.1\n",
        "0.035 1.0\n",
        "0.06 10.0\n",
        "0.29 100.0\n",
        "lamda_best:: -8.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 211,
       "text": [
        "0.029999999999999999"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q20:: with $log_{10}$$\\lambda$={2,1,...,-10} , previous result on whole data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge_regression_19_20(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.05 1e-10\n",
        "0.05 1e-09\n",
        "0.03 1e-08\n",
        "0.035 1e-07\n",
        "0.035 1e-06\n",
        "0.035 1e-05\n",
        "0.035 0.0001\n",
        "0.035 0.001\n",
        "0.035 0.01\n",
        "0.035 0.1\n",
        "0.035 1.0\n",
        "0.06 10.0\n",
        "0.29 100.0\n",
        "lamda_best:: -8.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 212,
       "text": [
        "(0.015, 0.02)"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}